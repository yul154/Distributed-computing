- 使用场景
 - 需要保证一个方法在同一时间内只能被同一个线程执行
- 实现方式:
 - 加锁和解锁
- 分布式锁实现
 - 基于数据库做分布式锁--乐观锁(基于版本号)和悲观锁(基于排它锁)
 - 基于 redis 做分布式锁:setnx(key,当前时间+过期时间)和Redlock机制
 - 基于 zookeeper 做分布式锁:临时有序节点来实现的分布式锁,Curator
 - 基于 Consul 做分布式锁

----
# 基于数据库如何实现分布式锁？有什么缺陷？

* 基于数据库表
  * 创建一张锁表，然后通过操作该表中的数据来实现了
  *  当我们想要获得锁的时候，就可以在该表中增加一条记录，想要释放锁的时候就删除这条记录

* 基于悲观锁
  * 在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。
  * 如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。 具体响应方式由开发者根据实际需要决定。
  * 如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。
  * 其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。

* 基于乐观锁
  *  乐观并发控制
    *  假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据
    *  在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。
    *  如果其他事务有更新的话，正在提交的事务会进行回滚
  * 使用版本号时，可以在数据初始化时指定一个版本号，每次对数据的更新操作都对版本号执行+1操作
   
   
对数据库依赖，开销问题，行锁变表锁问题，无法解决数据库单点和可重入的问题

---
# 基于redis如何实现分布式锁

## 最基本的Jedis方案

* 加锁： `set NX PX` + 重试 + 重试间隔
* 解锁： 采用lua脚本： 在删除key之前，一定要判断服务A持有的value与Redis内存储的value是否一致。如果贸然使用服务A持有的key来删除锁，则会误将服务B的锁释放掉

## 基于RedLock实现分布式锁

两个服务A、B都希望获得锁，有一个包含了5个redis master的Redis Cluster
* 客户端获取当前时间戳，单位: 毫秒 服务A轮寻每个master节点，尝试创建锁。(这里锁的过期时间比较短，一般就几十毫秒) 
  * RedLock算法会尝试在大多数节点上分别创建锁，假如节点总数为n，那么大多数节点指的是n/2+1。
* 客户端计算成功建立完锁的时间，如果建锁时间小于超时时间，就可以判定锁创建成功。如果锁创建失败，则依次(遍历master节点)删除锁。
* 只要有其它服务创建过分布式锁，那么当前服务就必须轮寻尝试获取锁。

##  基于Redisson实现分布式锁

1. 线程去获取锁，获取成功: 执行lua脚本，保存数据到redis数据库。
2. 线程去获取锁，获取失败: 订阅了解锁消息，然后再尝试获取锁，获取成功后，执行lua脚本，保存数据到redis数据库。


如果这个时候客户端B来尝试加锁，执行了同样的一段lua脚本。
1. 第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在。
2. 第二个if判断，判断myLock锁key的hash数据结构中，是否包含客户端B的ID，但明显没有，那么客户端B会获取到pttl myLock返回的一个数字，代表myLock这个锁key的剩余生存时间。
3. 此时客户端B会进入一个while循环，不听的尝试加锁。

WatchDog
* 客户端A加锁的锁key默认生存时间只有30秒，如果超过了30秒，解锁
* 客户端A还想一直持有这把锁，客户端A一旦加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间。


## 方案比较
* 借助Redis实现分布式锁时，有一个共同的缺陷: 当获取锁被决绝后，需要不断的循环，重新发送获取锁(创建key)的请求，直到请求成功。这就造成空转，浪费宝贵的CPU资源
* RedLock算法本身有争议，并不能保证健壮性。
* Redisson实现分布式锁时，除了将key新增到某个指定的master节点外，还需要由master自动异步的将key和value等数据同步至绑定的slave节点上。
  * 那么问题来了，如果master没来得及同步数据，突然发生宕机，那么通过故障转移和主备切换，slave节点被迅速升级为master节点，新的客户端加锁成功，
  * 旧的客户端的watch dog发现key存在，误以为旧客户端仍然持有这把锁，这就导致同时存在多个客户端持有同名锁的问题了

----
# 基于zookeeper现分布式锁

* 顺序节点 : 创建一个用于发号的节点“/test/lock”，然后以它为父亲节点的前缀为“/test/lock/seq-”依次发号
* 获得最小号得锁 : 由于序号的递增性，可以规定排号最小的那个获得锁。所以，每个线程在尝试占用锁之前，首先判断自己是排号是不是当前最小，如果是，则获取锁
* 节点监听机制 : 每个线程抢占锁之前，先抢号创建自己的ZNode。同样，释放锁的时候，就需要删除抢号的Znode。
  * 抢号成功后，如果不是排号最小的节点，就处于等待通知的状态, 只需要等前一个Znode 的通知就可以了。
  * 当前一个Znode 删除的时候，就是轮到了自己占有锁的时候。第一个通知第二个、第二个通知第三个，击鼓传花似的依次向后。
