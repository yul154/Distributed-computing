微服务
- 微服务的演化
- 微服务通信
- 微服务的负载
- 容错
- 消息队列
- 一致性
- 数据库
  - 分库分表
  - 读写分离
  - 唯一ID
  - 主从同步
  - 缓存
    -  热KEY
    -  缓存击穿
    -  穿透
    -  雪崩
- 稳定性


----
# 微服务

> 为什么要用微服务，解决什么问题

> 微服务设计思想？为什么需要这样设计？好处？

## 单体服务的短板

* 开发效率低：所有的开发在一个项目改代码，递交代码相互等待，代码冲突不断
* 代码维护难：代码功能耦合在一起，新人不知道何从下手
* 部署不灵活：构建时间长，任何小修改必须重新构建整个项目，这个过程往往很长
* 稳定性不高：一个微不足道的小问题，可以导致整个应用挂掉
* 扩展性不够：无法满足高并发情况下的业务需求

### 从高并发的角度
单体服务 : 所有业务服务都在一个项目里，部署在一台物理机器上。所有的业务包括你的交易系统、会员信息、库存、商品等等都夹杂在一起

* 机器挂了所有的业务全部无法使用了 
   * 集群架构的架构,水平拓展横向扩容,通过负载均衡把压力流量分摊到不同的机器上
* 一个项目里维护所有的业务场景使开发和代码维护变得越来越困难
  *  微服务的架构模式, 把每个独立的业务拆分开独立部署，开发和维护的成本降低，集群能承受的压力也提高了



### 微服务设计思想

将单一应用程序划分成一组小的服务，每个服务运行独立的自己的进程中，服务之间互相协调、互相配合，形成一个松耦合、功能隔离的服务架构

#### 垂直拆分

微服务作为 SOA（Service Oriented Architecture）思想的一种具体实践，按照不同的业务系统做垂直拆分
* 按业务系统对单体应用做垂直拆分，不同的业务线完全可以独立配备产品经历与工程师同步开发维护，将不同业务线解耦出来有不同团队维护
* 垂直拆分将各业务子系统解耦出来

<img width="356" alt="Screen Shot 2021-12-30 at 2 06 03 PM" src="https://user-images.githubusercontent.com/27160394/147726075-6e7aa7c2-0c5f-493b-bb1c-2752eacfc4f8.png">


#### 水平拆分

每次请求在不同阶段遇到的瓶颈与负载是不一样的，因此我们对可以使用水平拆分的思路对服务进行拆分

<img width="373" alt="Screen Shot 2021-12-30 at 2 06 50 PM" src="https://user-images.githubusercontent.com/27160394/147726119-ee9dc315-12dd-4804-8e6e-fc4cc225948a.png">

对系统即做垂直拆分也做水分拆分，那么就有了微服务的样子



### 用微服务解决什么问题
* 代码到处拷贝: A业务先写了一套用户服务的代码，这个时候业务线B也需要用户服务可能就是直接拷贝过来A的代码
* 不易扩展，数据库耦合:

###  微服务架构的重要特征：
> 微服务架构指的是将大型复杂系统按功能或者业务需求垂直切分成更小的子系统，这些子系统以独立部署的子进程存在

* 整个应用程序被拆分成相互独立但包含多个内部模块的子进程。
* 与模块化的单体应用（Modular Monoliths）或 SOA 相反，微服务应用程序根据业务范围或领域垂直拆分。
* 微服务边界是外部的，微服务之间通过网络调用（RPC 或消息）相互通信。
* 微服务是独立的进程，它们可以独立部署。
* 它们以轻量级的方式进行通信，不需要任何智能通信通道。

#### 微服务架构的优点
* 每个独立的业务拆分开独立部署，开发和维护的成本降低
* 集群能承受的压力也提高了
* 服务可以按需动态扩容
* 



#### 微服务挑战

* API Gateway
* 服务间调用
* 服务发现
* 服务容错
* 分布式部署，调用的复杂性高
* 数据调用


### 分布式和微服务的区别

分布式：一个业务分拆多个子业务，部署在不同的服务器上
* 由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。
* 分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。
* 其目的是利用更多的机器，处理更多的数据。




## 微服务通信 

### Dubbo
1. 服务启动的时候，provider和consumer根据配置信息，连接到注册中心register，分别向注册中心注册和订阅服务
2. register根据服务订阅关系，返回provider信息到consumer，同时consumer会把provider信息缓存到本地。如果信息有变更，consumer会收到来自register的推送
consumer生成代理对象，同时根据负载均衡策略，选择一台provider，同时定时向monitor记录接口的调用次数和时间信息
拿到代理对象之后，consumer通过代理对象发起接口调用
provider收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现

#### Dubbo负载均衡策略
* 加权随机: servers = abc，他们对应的权重为 weights = 5,3,2，权重总和为10。现在把这些权重值平铺在一维坐标值上
* 每个服务提供者对应一个活跃数 active
* 一致性hash：通过hash算法，把provider的invoke和随机节点生成hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环

> 一致性HASH解决什么问题


## 消息队列
>  削峰填谷、解耦

### 消息可靠性

**生产者丢失**
* 生产者丢失消息的可能点在于程序发送失败抛异常了没有重试处理
  * 异步有回调
  * 异步无回调: 异步发送+回调通知+本地消息表
  * 同步发送的一般不会出现这样使用方式 

**MQ丢失**
* RocketMQ分为同步刷盘和异步刷盘两种方式: 通过设置为同步刷盘的方式来保证消息可靠性
* Kafka: acks=all,要求每个partion至少有2个副本,会要求leader至少感知到一个follower还保持着连接

**消费者丢失**
* RocketMQ默认是需要消费者回复ack确认，
* kafka需要手动开启配置关闭自动offset。

### 消息的最终一致性
半事务消息
1. 生产者先发送一条半事务消息到MQ
2. MQ收到消息后返回ack确认
3. 生产者开始执行本地事务
4. 如果事务执行成功发送commit到MQ，失败发送rollback
5. 如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查
6. 生产者查询事务执行最终状态
7. 根据查询事务状态再次提交二次确认

-----
# 数据库

最终所有的流量的查询和写入都落在数据库上，数据库是支撑系统高并发能力的核心。怎么降低数据库的压力，提升数据库的性能是支撑高并发的基石
* 读写分离
* 分库分表

## 读写分离
> 对于整个系统而言，流量应该是一个漏斗的形式

* 对于系统来说读是大于写的，这时候可以通过读写分离的方式来降低数据库的压力
* 读写分离也就相当于数据库集群的方式降低了单节点的压力

## 分库分表
> 面对数据的急剧增长，原来的单库单表的存储方式已经无法支撑整个业务的发展

针对微服务而言垂直的分库本身已经是做过的

### 水平分表
现在日订单1000万，我们大部分的场景来源于C端
* 我们可以用user_id作为sharding_key
* 数据查询支持到最近3个月的订单
* 超过3个月的做归档处理，
* 那么3个月的数据量就是9亿，可以分1024张表，
* 那么每张表的数据大概就在100万左右。

用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。


### 分表后的ID唯一性
1. 设定步长
2. 分布式ID
3. 分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用



### 主从同步原理

1. master提交完事务后，写入binlog
2. slave连接到master，获取binlog
3. master创建dump线程，推送binglog到slave
4. slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中
5. slave再开启一个sql线程读取relay log事件并在slave执行，完成同步
6. slave记录自己的binglog


* 半同步复制 : 半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。


## 缓存

* 引入缓存事先预热可以大幅降低对数据库的压力

### 热key问题
> 突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩

* 提前把热key打散到不同的服务器，降低压力
* 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询


### 缓存击穿
* 加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。
* 将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。


### 缓存穿透
> 查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样

* 加一层布隆过滤器
  * 布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的K个点，同时把他们置为1。
  * 这样当用户再次来查询A，而A在布隆过滤器值为0，直接返回，就不会产生击穿请求打到DB了

### 缓存雪崩
> 某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上

* 针对不同key设置不同的过期时间，避免同时过期
* 限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB
* 二级缓存，同热key的方案。


# 稳定性
* 熔断
* 限流
* 降级
* 预案 : 就算是有统一配置中心，在业务的高峰期也是不允许做出任何的变更的，但是通过配置合理的预案可以在紧急的时候做一些修改
* 核对 : 针对各种分布式系统产生的分布式事务一致性或者受到攻击导致的数据异常，非常需要核对平台来做最后的兜底的数据验证




