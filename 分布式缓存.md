# 缓存实现

## memcached缓存

memcached仅支持基础的key-value键值对类型数据存储

memcached集群环境实际就是一个个memcached服务器的堆积，环境搭建较为简单；
* cache的分布式主要是在客户端实现，通过客户端的路由处理来达到分布式解决方案的目的。
* 客户端做路由的原理 : 应用服务器在每次存取某key的value时，通过某种算法把key映射到某台memcached服务器nodeA上，因此这个key所有操作都在nodeA上

### memcached客户端采用一致性hash算法作为路由策略

一致性hash算法除了计算key的hash值外，还会计算每个server对应的hash值，然后将这些hash值映射到一个有限的值域上（比如0~2^32）
* 通过寻找hash值大于hash(key)的最小server作为存储该key数据的目标server
* 如果找不到，则直接把具有最小hash值的server作为目标server


### memcached的内存管理机制

* slab是一个内存块，它是memcached一次申请内存的最小单位
  * 在启动memcached的时候一般会使用参数`-m`指定其可用内存，
  * 启动的那一刻并没有把所有的内存就全部分配出去了，只有在需要的时候才会去申请，而且每次申请一定是一个slab
* 一个slab由若干个大小相等的chunk组成。每个chunk中都保存了一个item结构体、一对key和value
  * 同一个slab中chunk的大小相等的，但是在不同的slab中chunk的大小并不一定相等
  * 在memcached中按照chunk的大小不同，可以把slab分为很多种类（class）
 
 memcached内存管理采取预分配、分组管理的方式
 * 分组管理 : 在memcached中按照chunk的大小不同，可以把slab分为很多种类（class）
 * 预分配 : 向memcached添加一个item时候，memcached首先会根据item的大小，来选择最合适的slab class：
 


Summary
* 对于key-value信息，最好不要超过1m的大小
* 如果用户数据大于1m，则memcached会将其切割，放到多个chunk内
* memcached采用的LRU清理策略，合理甚至过期时间，提高命中率
* 使用memcached分布式集群是较好的选择，搭建与操作使用都比较简单；分布式集群在单点故障时，只影响小部分数据异常


# Redis缓存

* 它可以存储键值对与5种不同类型的值之间的映射
* 可以将存储在内存的键值对数据持久化到硬盘
* 可以使用复制特性来扩展读性能
* 还可以使用客户端分片来扩展写性能。

<img width="465" alt="Screen Shot 2021-12-19 at 1 56 37 PM" src="https://user-images.githubusercontent.com/27160394/146665569-04d30692-6951-4305-928d-44627a77799e.png">



## I/O

Redis使用单线程的I/O复用模型，自己封装了一个简单的AeEvent事件处理框架，主要实现了epoll、kqueue和select。
* 对于单纯只有I/O操作来说，单线程可以将速度优势发挥到最大，但是Redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型实际会严重影响整体吞吐量，CPU计算过程中，整个I/O调度都是被阻塞住的，在这些特殊场景的使用中，需要额外的考虑。
* 相较于memcached的预分配内存管理，Redis使用现场申请内存的方式来存储数据，并且很少使用free-list等方式来优化内存分配，会在一定程度上存在内存碎片。
* Redis跟据存储命令参数，会把带过期时间的数据单独存放在一起，并把它们称为临时数据，非临时数据是永远不会被剔除的，即便物理内存不够，导致swap也不会剔除任何非临时数据（但会尝试剔除部分临时数据）。


## Redis持久化方式

* RDB ：定时快照
  * 在Redis内部一个定时器事件，每隔固定时间去检查当前数据发生的改变次数与时间是否满足配置的持久化触发的条件
  * 如果满足则通过操作系统fork调用来创建出一个子进程，这个子进程默认会与父进程共享相同的地址空间，这时就可以通过子进程来遍历整个内存来进行存储操作
  * 当有写入时由操作系统按照内存页（page）为单位来进行copy-on-write保证父子进程之间不会互相影响
  * 它的缺点是快照只是代表一段时间内的内存映像，所以系统重启会丢失上次快照与重启之间所有的数据
* AOF
  * aof方式实际类似MySQl的基于语句的binlog方式，每条会使Redis内存数据发生改变的命令都会追加到一个log文件中，也就是说这个log文件就是Redis的持久化数据
  * aof的方式的主要缺点是追加log文件可能导致体积过大，当系统重启恢复数据时如果是aof的方式则加载数据会非常慢，几十G的数据可能需要几小时才能加载完


Redis的持久化使用了Buffer I/O
* Redis对持久化文件的写入和读取操作都会使用物理内存的Page Cache，而大多数数据库系统会使用Direct I/O来绕过这层Page Cache并自行维护一个数据的Cache。
* 而当Redis的持久化文件过大（尤其是快照文件）并对其进行读写时，磁盘文件中的数据都会被加载到物理内存中作为操作系统对该文件的一层Cache，而这层Cache的数据与Redis内存中管理的数据实际是重复存储的。
* 虽然内核在物理内存紧张时会做Page Cache的剔除工作，但内核很可能认为某块Page Cache更重要，而让你的进程开始Swap，这时你的系统就会开始出现不稳定或者崩溃了，因此在持久化配置后，针对内存使用需要实时监控观察

## Redis Cluster
> 一个实现了分布式且允许单点故障的Redis高级版本

* 节点与节点之间通过二进制协议进行通信，节点与客户端之间通过ascii协议进行通信
*  在数据的放置策略上，Redis Cluster将整个key的数值域分成2的14次方16384个hash槽，每个节点上可以存储一个或多个hash槽，也就是说当前Redis Cluster支持的最大节点数就是16384
*  Redis Cluster使用的分布式算法也很简单：`crc16( key ) % HASH_SLOTS_NUMBER`
```
数据hash分布在不同的Redis节点实例上； M/S的切换采用Sentinel；
写：只会写master Instance，从sentinel获取当前的master Instance； 
读：从Redis Node中基于权重选取一个Redis Instance读取，失败/超时则轮询其他Instance；
Redis本身就很好的支持读写分离，在单进程的I/O场景下，可以有效的避免主库的阻塞风险；
````

## Redis 事务



## Redis的多种Web应用场景
*  在主页中显示最新的项目列表：Redis使用的是常驻内存的缓存，速度非常快。
    *  LPUSH用来插入一个内容ID，作为关键字存储在列表头部。LTRIM用来限制列表中的项目数最多为5000。如果用户需要的检索的数据量超越这个缓存容量，这时才需要把请求发送到数据库。
* 删除和过滤：如果一篇文章被删除，可以使用LREM从缓存中彻底清除掉
*  排行榜及相关问题：排行榜（leader board）按照得分进行排序。
    *  ZADD命令可以直接实现这个功能，而ZREVRANGE命令可以用来按照得分来获取前100名的用户，ZRANK可以用来获取用户排名，非常直接而且操作容易
* 按照用户投票和时间排序
  * 排行榜，得分会随着时间变化。LPUSH和LTRIM命令结合运用，把文章添加到一个列表中。一项后台任务用来获取列表，并重新计算列表的排序
  * ZADD命令用来按照新的顺序填充生成列表。列表可以实现非常快速的检索，即使是负载很重的站点。
* 过期项目处理
  *  使用Unix时间作为关键字，用来保持列表能够按时间排序。
  *  对current_time和time_to_live进行检索，完成查找过期项目的艰巨任务。另一项后台任务使用ZRANGE…WITHSCORES进行查询，删除过期的条目
*  计数：进行各种数据统计的用途是非常广泛的，比如想知道什么时候封锁一个IP地址
    *  INCRBY命令让这些变得很容易，通过原子递增保持计数；
    *  GETSET用来重置计数器；过期属性用来确认一个关键字什么时候应该删除
* 特定时间内的特定项目：这是特定访问者的问题
    * 可以通过给每次页面浏览使用SADD命令来解决。SADD不会将已经存在的成员添加到一个集合
* Pub/Sub：在更新中保持用户对数据的映射是系统中的一个普遍任务
    * Redis的pub/sub功能使用了SUBSCRIBE、UNSUBSCRIBE和PUBLISH命令，让这个变得更加容易
*  队列：在当前的编程中队列随处可见。除了push和pop类型的命令之外，Redis还有阻塞队列的命令，能够让一个程序在执行时被另一个程序添加到队列。
    * 实际工程中，对于缓存的应用可以有多种的实战方式，包括侵入式硬编码，抽象服务化应用，以及轻量的注解式使用等。本文将主要介绍下注解式方式
